[{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["os", "os"],
		["matplotlib.pyplot", "plt"]
	],
	"dataset description": "Housing data https://raw.githubusercontent.com/ageron/handson-ml2/master/",
	"question": "Try a Support Vector Machine regressor (sklearn.svm.SVR), with various hyperparameters such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Don\u2019t worry about what these hyperparameters mean for now. How does the best SVR predictor perform?",
	"code": "sol2.1.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "the usual Iris dataset",
	"question": "Implement Batch Gradient Descent with early stopping for Softmax Regression\n(without using Scikit-Learn).",
	"code": "sol4.12.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "moons dataset",
	"question": "Train and fine-tune a Decision Tree for the moons dataset.\na. Generate a moons dataset using make_moons(n_samples=10000, noise=0.4).\nb. Split it into a training set and a test set using train_test_split().\nc. Use grid search with cross-validation (with the help of the GridSearchCV\nclass) to find good hyperparameter values for a DecisionTreeClassifier.\nHint: try various values for max_leaf_nodes.\nd. Train it on the full training set using these hyperparameters, and measure\nyour model\u2019s performance on the test set. You should get roughly 85% to 87% accuracy.",
	"code": "sol6.7.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "moons dataset",
	"question": "Grow a forest.\na. Continuing the previous exercise, generate 1,000 subsets of the training set, each containing 100 instances selected randomly. Hint: you can use Scikit-Learn\u2019s ShuffleSplit class for this.\nb. Train one Decision Tree on each subset, using the best hyperparameter values found above. Evaluate these 1,000 Decision Trees on the test set. Since they were trained on smaller sets, these Decision Trees will likely perform worse than the first Decision Tree, achieving only about 80% accuracy.\nc. Now comes the magic. For each test set instance, generate the predictions of the 1,000 Decision Trees, and keep only the most frequent prediction (you can use SciPy\u2019s mode() function for this). This gives you majority-vote predictions over the test set.\nd. Evaluate these predictions on the test set: you should obtain a slightly higher accuracy than your first model (about 0.5 to 1.5% higher). Congratulations, you have trained a Random Forest classifier!",
	"code": "sol6.8.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "MNIST",
	"question": "Load the MNIST dataset (introduced in Chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing). Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set. Next, use PCA to reduce the dataset\u2019s dimensionality, with an explained variance ratio of 95%. Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster? Next evaluate the classifier on the test set: how does it compare to the previous classifier?",
	"code": "sol8.9.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "MNIST",
	"question": "Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib. You can use a scatterplot using 10 different colors to represent each image\u2019s target class. Alternatively, you can write colored digits at the location of each instance, or even plot scaled-down versions of the digit images themselves (if you plot all digits, the visualization will be too cluttered, so you should either draw a random sample or plot an instance only if no other instance has already been plotted at a close distance). You should get a nice visualization with well-separated clusters of digits. Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations.",
	"code": "sol8.10.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "MNIST",
	"question": "Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Try adding all the bells and whistles (i.e., save checkpoints, use early stopping, plot learning curves using TensorBoard, and so on).",
	"code": "sol10.10.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "california_housing  from sklearn.datasets import fetch_california_housing",
	"question": "Implement a custom layer that performs Layer Normalization:\na. The build() method should define two trainable weights \u03b1 and \u03b2, both of shape input_shape[-1:] and data type tf.float32. \u03b1 should be initialized with 1s, and \u03b2 with 0s.\nb. The call() method should compute the mean \u03bc and standard deviation \u03c3 of each instance's features. For this, you can use tf.nn.moments(inputs, axes=-1, keepdims=True), which returns the mean \u03bc and the variance \u03c32 of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return \u03b1\u2297(X - \u03bc)/(\u03c3 + \u03b5) + \u03b2, where \u2297 represents itemwise multiplication (*) and \u03b5 is a smoothing term (small constant to avoid division by zero, e.g., 0.001).\nc. Ensure that your custom layer produces the same (or very nearly the same) output as the keras.layers.LayerNormalization layer.",
	"code": "sol12.12.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "Fashion MNIST",
	"question": "Train a model using a custom training loop to tackle the Fashion MNIST dataset.\na. Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch.\nb. Try using a different optimizer with a different learning rate for the upper layers and the lower layers.",
	"code": "sol12.13.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "MNIST",
	"question": "Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.",
	"code": "sol14.9.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "generated dataset",
	"question": "Embedded Reber grammars were used by Hochreiter and Schmidhuber in their paper about LSTMs. They are artificial grammars that produce strings such as \"BPBTSXXVPSEPE.\" Check out Jenny Orr's nice introduction to this topic. Choose a particular embedded Reber grammar (such as the one represented on Jenny Orr's page), then train an RNN to identify whether a string respects that grammar or not. You will first need to write a function capable of generating a training batch containing about 50% strings that respect the grammar, and 50% that don't.",
	"code": "sol16.8.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "generated dataset",
	"question": "Train an Encoder\u2013Decoder model that can convert a date string from one format to another (e.g., from \"April 22, 2019\" to \"2019-04-22\").",
	"code": "sol16.9.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "openai-gpt",
	"question": "Use one of the recent language models (e.g., GPT) to generate more convincing Shakespearean text.",
	"code": "sol16.11.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "OpenAI LunarLander-v2 environment",
	"question": "Use policy gradients to solve OpenAI Gym's LunarLander-v2 environment. You will need to install the Box2D dependencies (%pip install -U gym[box2d]).",
	"code": "sol18.8.json"
}, {
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"]
	],
	"dataset description": "TF-Agents",
	"question": "Use TF-Agents to train an agent that can achieve a superhuman level at SpaceInvaders-v4 using any of the available algorithms.",
	"code": "sol18.9.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The MNIST dataset",
	"question": "Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set.",
	"code": "sol3.1.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The MNIST dataset",
	"question": "Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one pixel .5 Then, for each image in the training set, create four shifted copies(one per direction) and add them to the training set.Finally, train your best model on this expanded training set and measure its accuracy on the test set.",
	"code": "sol3.2.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"],
		["os", "os"],
		["urllib.request", "urllib.request"]
	],
	"dataset description": "A dataset of passengers on the Titanic, found at https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/.",
	"question": "Tackle the Titanic dataset. predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on.",
	"code": "sol3.3.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The iris dataset",
	"question": "Train a LinearSVC on a linearly separable dataset. Then train an SVC and a SGDClassifier on the same dataset. See if you can get them to produce roughly the same model.",
	"code": "sol5.8.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The MNIST dataset",
	"question": "Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers, you will need to use one - versus - all to classify all 10 digits.You may want to tune the hyperparameters using small validation sets to speed up the process. What accuracy can you reach ?",
	"code": "sol5.9.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The California Housing dataset in scikit",
	"question": "Train an SVM regressor on the California housing dataset.",
	"code": "sol5.10.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The MNIST dataset in scikit",
	"question": "Load the MNIST data (introduced in Chapter 3), and split it into a training set, a validation set, and a test set(e.g., use 50, 000 instances for training, 10,000 for validation, and 10, 000 for testing).Then train various classifiers, such as a Random Forest classifier, an Extra - Trees classifier, and an SVM.Next, try to combine them into an ensemble that outperforms them all on the validation set, using a soft or hard voting classifier.Once you have found one, try it on the test set.How much better does it perform compared to the individual classifiers ? ",
	"code": "sol7.8.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The MNIST dataset in scikit",
	"question": "Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image’ s class.Train a classifier on this new training set.Congratulations, you have just trained a blender, and together with the classifiers they form a stacking ensemble!Now let’ s evaluate the ensemble on the test set.For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble’ s pre‐ dictions.How does it compare to the voting classifier you trained earlier ? ",
	"code": "sol7.9.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The Olivetti faces dataset in scikit,",
	"question": "The classic Olivetti faces dataset contains 400 grayscale 64 × 64–pixel images of faces. Each image is flattened to a 1D vector of size 4,096. 40 different people were photographed (10 times each), and the usual task is to train a model that can predict which person is represented in each picture. Load the dataset using the sklearn.datasets.fetch_olivetti_faces() function.",
	"code": "sol9.10.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The Olivetti faces dataset in scikit.",
	"question": "Continuing with the Olivetti faces dataset, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set",
	"code": "sol9.11.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"]
	],
	"dataset description": "The Olivetti faces dataset in scikit.",
	"question": "Train a Gaussian mixture model on the Olivetti faces dataset. To speed up the algorithm, you should probably reduce the dataset's dimensionality (e.g., use PCA, preserving 99% of the variance).",
	"code": "sol9.12.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"],
		["tensorflow", "tf"]
	],
	"dataset description": "The Olivetti faces dataset in scikit.",
	"question": "a. Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function. b.Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset.You can load it with keras.datasets.cifar10.load_data().The dataset is composed of 60,000 32× 32– pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you 'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model' s architecture or hyperparameters. c.Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before ? Does it produce a better model ? How does it affect training speed ? d.Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self - normalizes(i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.). e.Try regularizing the model with alpha dropout.Then, without retraining your model, see if you can achieve better accuracy using MC Dropout. f.Retrain your model using 1 cycle scheduling and see if it improves training speed and model accuracy. ",
	"code": "sol11.8.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"],
		["tensorflow", "tf"]
	],
	"dataset description": "The fashion MNIST dataset in scikit.",
	"question": "Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized Example protobuf with two features: the serialized image (use tf.io.serialize_tensor() to serialize each image), and the label. Note: for large images, you could use tf.io.encode_jpeg() instead. This would save a lot of space, but it would lose a bit of image quality",
	"code": "so13.9.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"],
		["tensorflow", "tf"]
	],
	"dataset description": "The Large Movie Review Dataset, which contains 50,000 movies reviews from the Internet Movie Database. Found at http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz",
	"question": "a. Download the Large Movie Review Dataset, which contains 50,000 movies reviews from the Internet Movie Database. The data is organized in two directories, train and test, each containing a pos subdirectory with 12,500 positive reviews and a neg subdirectory with 12,500 negative reviews. Each review is stored in a separate text file. There are other files and folders (including preprocessed bag-of-words), but we will ignore them in this exercise. b.Split the test set into a validation set(15, 000) and a test set(10, 000). c.Use tf.data to create an efficient dataset for each set. d.Create a binary classification model, using a TextVectorization layer to preprocess each review.If the TextVectorization layer is not yet available (or if you like a challenge), try to create your own custom preprocessing layer: you can use the functions in the tf.strings package, for example lower() to make everything lowercase, regex_replace() to replace punctuation with spaces, and split() to split words on spaces.You should use a lookup table to output word indices, which must be prepared in the adapt() method. e.Add an Embedding layer and compute the mean embedding for each review, multiplied by the square root of the number of words(see Chapter 16).This rescaled mean embedding can then be passed to the rest of your model. f.Train the model and see what accuracy you get.Try to optimize your pipelines to make training as fast as possible. g.Use TFDS to load the same dataset more easily: tfds.load('imdb_reviews') ",
	"code": "sol13.10.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"],
		["tensorflow", "tf"]
	],
	"dataset description": "SketchRNN dataset",
	"question": "Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets",
	"code": "sol15.9.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"],
		["tensorflow", "tf"],
		["pandas", "pd"]
	],
	"dataset description": "The Bach chorales dataset. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Found at https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/jsb_chorales.tgz",
	"question": "Download the Bach chorales dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note's index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out Google's Coconet model, which was used for a nice Google doodle about Bach.",
	"code": "sol15.10.json"
},

{
	"packages": [
		["numpy", "np"],
		["scikit-learn", "sklearn"],
		["matplotlib", "mpl"],
		["tensorflow", "tf"],
		["pandas", "pd"]
	],
	"dataset description": "MNIST or CIFAR10 datasets",
	"question": "Try using a denoising autoencoder to pretrain an image classifier. You can use MNIST (the simplest option), or a more complex image dataset such as CIFAR10 if you want a bigger challenge. Regardless of the dataset you're using, follow these steps: Split the dataset into a training set and a test set.Train a deep denoising autoencoder on the full training set. Check that the images are fairly well reconstructed.Visualize the images that most activate each neuron in the coding layer. Build a classification DNN, reusing the lower layers of the autoencoder.Train it using only 500 images from the training set.Does it perform better with or without pretraining ? ",
	"code": "sol17.9.json"
}
]